## 基于 Scrapy + FastMCP 构建 WebFetch MCP Server

- [x] 初始化 data-extractor: 我需要一个可用于爬取网页内容的 MCP Server, 需要简单好用,页面读取能力稳定,请参考成熟技术方案,基于 Scrapy + FastMCP 帮我搭建一个这样的 MCP Server,以满足我在商业工具中长期的需求.
- [x] use uv: 将项目的包管理工具更换为 uv
- [x] 在 README.md 的 MCP Client 配置指引中帮我添加通过 Repo 方式和 uv 指令启动该 MCP Server 的指引
- [x] 根据项目名称、结构、GitHub Repo 地址等(git@github.com:ThreeFish-AI/scrapy-mcp.git)信息，修正 README.md 中类似 <repository-url> 的占位符、模块名、服务名、路径等
- [x] 将 Python 版本的最低要求改为 3.12，注意相关依赖的可用性
- [x] 解决 uv run data-extractor 启动异常问题

## 新增 MCP 工具：页面转 Markdown 文档，支持批处理

- [x] 新增 MCP 工具：页面转 Markdown 文档，支持批处理；为新增的 MCP 工具添加说明文档（README.md 中）；为新增的 MCP 工具添加单元测试，并补全测试说明文档；自动化测试过程；执行测试验证功能无误。
- [ ] 为「页面转 Markdown 文档」过程添加 Markdown 格式化功能。并为新增功能添加说明文档（README.md 中）；为新增功能添加单元测试，并补全测试说明文档；自动化测试过程；执行测试验证功能无误。
- [ ] 补全和强化集成测试。

## 新增 MCP transport 支持：StreamableHTTP

- [ ] 新增 MCP transport 支持：StreamableHTTP，令该 MCP Server 可以部署到云端被远程调用；为新增的 transport 支持添加说明文档（README.md 中）；为新增的 transport 支持添加单元测试，并补全测试说明文档；自动化测试过程；执行测试验证功能无误。